{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from mnist import MNIST\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "%matplotlib inline\n",
    "mndata = MNIST('./python-mnist/data')\n",
    "images_training, labels_training = mndata.load_training()\n",
    "images_testing, labels_testing = mndata.load_testing()  \n",
    "print(len(images_testing))\n",
    "print(len(images_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import sklearn \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from pylab import *\n",
    "!pip install statsmodels --user \n",
    "import statsmodels.api as sm # recommended import according to the docs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_X = np.matrix(images_training[:20000]).T \n",
    "training_Y = np.matrix(labels_training[:20000])\n",
    "testing_X = np.matrix(images_testing).T \n",
    "testing_Y = np.matrix(labels_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepossing the data \n",
    "training_X = training_X/127.5-1\n",
    "testing_X = testing_X/127.5-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data prepossing\n",
    "def Predata(digit,training_Y,testing_Y):\n",
    "    testing_Y = (testing_Y == digit).astype(np.int)\n",
    "    testing_Y[testing_Y==0] = -1 \n",
    "    training_Y = (training_Y == digit).astype(np.int)\n",
    "    training_Y[training_Y==0] = -1 \n",
    "    return training_Y,testing_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time \n",
    "for i in range(10):\n",
    "    training_Y_,testing_Y_=Predata(i,training_Y,testing_Y)\n",
    "#     clf = SVC(random_state=0,C=2,kernel=\"rbf\",gamma=0.0625)\n",
    "    clf = SVC(random_state=0,C=2,kernel=\"linear\")\n",
    "    clf.fit(training_X.T,np.ravel(training_Y_.T))\n",
    "    score = clf.score(testing_X.T,np.ravel(testing_Y_.T))\n",
    "    print(\"Tetsing error for digit {} is {}\".format(i,1-score))\n",
    "    print(\"number of support vector is {}\".format(clf.dual_coef_.shape[1]))\n",
    "    dual = clf.dual_coef_\n",
    "    side1=dual[0,:clf.n_support_[0]]\n",
    "    side2=dual[0,clf.n_support_[0]:]\n",
    "    index1 = (-side1).argsort()[:3]\n",
    "    index2 = (side2).argsort()[:3]\n",
    "#     print(clf.predict(training_X.T[clf.support_[index1[0]],:]))\n",
    "#     print(clf.predict(training_X.T[clf.support_[clf.n_support_[0]+index2[0]],:]))\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(training_X.T[clf.support_[index1[0]],:].reshape(28,28))\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(training_X.T[clf.support_[index1[1]],:].reshape(28,28))\n",
    "    plt.title(\"support vector to -1 class\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(training_X.T[clf.support_[index1[2]],:].reshape(28,28))\n",
    "    plt.show()\n",
    "    # support vector to the 1 class \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(training_X.T[clf.support_[clf.n_support_[0]+index2[0]],:].reshape(28,28))\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(training_X.T[clf.support_[clf.n_support_[0]+index2[1]],:].reshape(28,28))\n",
    "    plt.title(\"support vector to 1 class\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(training_X.T[clf.support_[clf.n_support_[0]+index2[2]],:].reshape(28,28))\n",
    "    plt.show()\n",
    "    Y = clf.decision_function(training_X.T)\n",
    "    Margin = np.multiply(Y,training_Y_)\n",
    "    Margin1 = np.ravel(Margin)\n",
    "    \n",
    "    sample = np.random.uniform(0, 1, 50)\n",
    "    sample=Margin1\n",
    "    ecdf = sm.distributions.ECDF(sample)\n",
    "    dsum = sum(sample);\n",
    "    normalized_data = sample/dsum;\n",
    "    x = np.linspace(min(sample), max(sample),10000)\n",
    "    y = ecdf(x)\n",
    "    plt.step(x, y)\n",
    "    plt.xlabel(\"Margin\")\n",
    "    plt.ylabel(\"cdf\")\n",
    "    plt.show()\n",
    "    print(time.time()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
